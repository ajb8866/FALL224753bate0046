---
title: 'Ass 2: Template'
author: "Averi Bates"
date: '`r format(Sys.Date(),format="%A, %B %d, %Y")`'
output: 
  html_document:
    df_print: paged
    fig_caption: true
    highlights: pygments
    number_sections: no
    theme: spacelab
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE, fig.align='center'}
knitr::opts_chunk$set(echo = TRUE)
```

# Questions{17/17}

## Q 1

### a)

The probability that an expert will fail to identify a match print is 7.88%. 


### b) 
The probability that an expert will fail to identify a match print is 25.45%. 


### c) 
The participant is more likely to be a novice because the probability that a novice would fail is much higher then an expert's.


## Q 2
```{r}
plot(1:10)
```

### a) 

$P(+ | user) = \frac{P(+ \cap user )}{P(user)}$

$P(+ \cap user) = \frac{users\space testing\space positive}{sample \space size} = \frac{50}{1000}$

$P(user) = \frac{users}{sample \space size} = \frac{100}{1000}$

 $\frac{P(+ \cap user )}{P(user)} = \frac{\frac{50}{1000}}{\frac{100}{1000}}$
 
 $=0.5$
 
There is 50% probability that a user will yield a positive test result.

### b) 

 $P(-|nonuser) = \frac{P(-\cap nonuser)}{P(nonuser)}$
 
 $P(-\cap nonuser) = \frac{nonusers\space testing\space negative}{sample \space size} = \frac{891}{1000}$
 
 $P(nonuser) = \frac{nonusers}{sample \space size} = \frac{900}{1000}$ 
 
 $\frac{P(-\cap nonuser)}{P(nonuser)} =891/900$
 
The probability that a drug test for testosterone will yield a negative result is 99%. 


### c) 

$P(u | +) = \frac{P(u)P(+|u)}{P(u)P(+|u)+P(nonuser)P(+|nonuser)}$


$P(user) = \frac{100}{1000}$

$P(+|u) = \frac{\frac{50}{1000}}{.1}$, $P(+|nonuser) = \frac{\frac{9}{1000}}{.9}$

$P(u|+) = \frac{(.1)(.5)}{(.1)(.5)+(.9)(.01)} = .8475$

The probability the probability that the athlete is really doping is 84.75%. 

## Q 3
Using two sets, _A_ and _B_, with lengths *c* and *d* respectively it is clear the number of possible ways that a single element from set _A_ can be combined with all elements in set _B_ would have a length equal to *d*. If we repeat this for all elements of _A_ we would have _A_ * _B_ number of possible combinations if one random element is chosen from each set. 
Using two sets, _A_, _B_ and _C_, with lengths *d*, *e*, and *f* respectively. Now following the procedure from above we can fix the element of _A_ and _B_ and change _C_. This would give *f* number of possible combinations of a given fix element from set _A_ and _B_. Then by changing one of the other elements in a single set at a time we realize that the number of possible combinations between  _A_, _B_ and _C_ would be *d* * *e* * *f*. This pattern would extrapolate to higher number of set combinations implying that the number of possible ways that one random element from each subset would be chosen is equal to the multiplication of the lengths of each set. 

## Q 4
For this theorem we need find how many distinct ways we can choose *n* elements from a set with N elements. We will look at each pick individually until we get *n* elements. The first pick would have N possible elements to choose from. The second element would have one less choice thus having N-1 possible options to pick. The third element will have one less possible choice compared the second pick thus having N-2 Possible combinations. The pattern would repeat until we arrive to the *n* pick which would have N-n+1 possibilities. Thus, to find the number of possible ways to pick this *n* elements from a set with N elements we need to use Theorem 3.1 proven above. The theorem states the length of each subset would be the length that we just found for each pick and the number of sets would be the number of picks that we are doing. using this theorem we would get the following equation

${N \choose n} = N*(N-1)*(N-2)* \cdots *(N-n+1)\\$ 

which can be rewritten as 

${N \choose n} = \frac{N!}{(N-n)!}\\$


## Q 5
We can arrange N different elements in k positions is $N!$ which by using theorem 3.1 would become 

$(A)(n_1!)(n_2!)\cdots(n_k!)\\$ 

after rearranging the elements we get 

$A = \frac{N!}{n_1!n_!\cdots n_k!}\\$


## Q 6
This theorem Rule can be derived by the Partitions Rule, seen above. 
For this rule we want to select n samples from N and and make two groups. These groups are the n that is selected from the N-n and the remaining that are not selected. 

The equation describing this theorem is. 

$N\choose n$ = $\frac{N!}{n!(N-n)!}\\$

## Q 7

### a)
```{r}
0.09+0.30+0.37+0.20+0.04
```
The probabilities for Y equal 1. 

### b)
$P(3\cup 4) = P(3) + P(4) = 0.2+0.04 = 0.24 = 24\%\\$

### c)

$P(0 \cup 1) = P(0) + P(1) = 0.09+0.3 = 0.39 = 39\%\\$

## Q 8

```{r}
#creating table
table = matrix(NA, nrow =21 ,ncol = 2)
#labeling the table 
colnames(table) = c("# Apps","p(y)")
#Imputing the values of the table
table[,1] = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
table[,2] = c(0.17,0.1,0.11,0.11,0.1,0.1,0.07,0.05,0.03,0.02,0.02,0.02,0.02,0.02,0.01,0.01,0.01,0.01,0.01,0.005,0.005)
#printing the table
library(knitr)
kable(table, caption = "Summary Table for Downloaded Apps")
```


### a)

The sample space is finite as the sample space equals $\Omega = \{1,2,3,\cdots,20 \}$. Thus,the random variable is discrete

### b) 

```{r}
0.02+0.02+0.02+0.02+0.01+0.01+0.01+0.01+0.01+0.005+0.005
```

### c)

```{r}
# mean 
mean = 0
for (i in 1:21){
mean = mean + c(table[i,1])*c(table[i,2])
}
mean
# variance
EX2 = 0
for (i in 1:21){
  EX2 =  EX2 + (c(table[i,1]))^2*c(table[i,2])
}
var = EX2-(mean^2)
var
```
### d) 

$P(|X-\mu| \geq \epsilon) \leq \frac{Var(X)}{\epsilon^2}\\$

which is rearranged as  

$P(-\epsilon+\mu \leq X \leq \epsilon+\mu ) \geq 1-\frac{Var(X)}{\epsilon^2}\\$

when looking at 
$1-\frac{Var(X)}{\epsilon^2} = 0.75\\$

$\therefore \epsilon = \sqrt{\frac{Var(X)}{1+0.75}}  = \sqrt{\frac{19.85597}{1.75}} = 3.368423\\$

 the interval would be 

$-\epsilon+\mu \leq X \leq \epsilon + \mu\\$ 

which is 

$-3.368423 +4.655 \leq X \leq -3.368423 +4.655\\$

the simplified interval would equal

$$1.286577 \leq X \leq 8.023423\\ $$


## Q 9

### a)
Binomial Probability 

$P(x=10) = p(10) = \binom{25}{10}.7^{10}.3^{25-10} = 0.0013$


### b)

Probability that Y is less than or equal to 5 is a lower tail probability. 

```{r}
pbinom(5,25,0.7)
```

### c) 

$mu = np = (25)(0.7) = 17.5$

$\sigma^2 = npq = (25)(0.7)(0.30) = 5.25$

$\sigma = \sqrt{\sigma^2} = \sqrt(5.25) = 2.2912$

### d)

We expect 17.5 foreign students give or take 2.29 in a random sample to be engineering students (these values would be rounded to the nearest whole as you can not have continuous values of students).

## Q 10
### a)
N = 50 because there are 50 trains that require an assignment. 

The denominator is 5^10 because there are 5 trains at each 10 tracks. 

```{r}
factorial(50)/(factorial(5)^10)*(0.1^5)^10
```

### b)
We want to know if there will be less than two trains assigned at Track #1. 
This is a binomial distribution. 

```{r}
dbinom(0,50,0.1)+dbinom(1,50,0.1)
```
The probability that Track # 1 is underutilized is 0.0338%. 

## Q 11

### a) 

This is a geometric distribution because you are interviewing consumers until there is a success. 

The formula for the probability distribution of y is 

$p(y) = pq^{y-1}\\$


### b) 
$E(y) = \mu = \frac{1}{p}=\frac{1}{0.4}\\$

The expected value would be the inverse of the success probability meaning as the success rate is lower more trials will be needed before obtaining the first success.

### c) 

P(Y=1)

$P(y) = pq^{y-1} = (0.4)(0.6)^{1-1} = 0.4\\$

```{r}
0.4*0.6^(1-1)
```

### d) 

$P(Y<=2)\\$

$P(y<=2) = p(1)+p(2) = (0.4)(0.6)^{1-1} + (0.4)(0.6)^{2-1} = 0.4+ 0.24 = 0.64\\$

$P(y>2) = 1-0.64 = 0.36\\$ 


## Q 12

### a) 

The excepted number/mean 

$\mu = \frac{nr}{N} = \frac{80}{209} = .3828\\$
 
### b)  

Probability that 4 out of the 10 selected treat hazardous waste on-site 

$P(x=4) = \frac{\binom{8}{4} \binom{201}{6}}{\binom{209}{10}} = .00017\\$ 

 

## Q 13

### a) 
Variance
$\mu = \sigma^2$ so $\sigma^2 = .03$

### b) 
For Poisson Distribution to be applicable 3 requirements have to be meet. 

1. The experiment consists of counting the number of times Y a particular (rare)
event occurs during a given unit of time or in a given area or volume (or weight,
distance, or any other unit of measurement).

2. The probability that an event occurs in a given unit of time, area, or volume is the
same for all the units. Also, units are mutually exclusive.

3. The number of events that occur in one unit of time, area, or volume is independent of the number that occur in other units.

### c) 

Probability Distribution is needed to find the probability of a deep-draft U.S. flag vessel having no casualties in a 3-year time period

$\lambda =.03$  

$\quad y(3) = \frac{.03^3\times e^{-.03}}{3!} =4.367*10^{-6} $

```{r}
(0.03^3)*2.71828^(-0.03)/(3*2*1)
```
## Q 14

### a)

$1 = \int_{0}^{1}2*c-c*y dy\\$

$\therefore 1= [2*c*y-\frac{c*y^2}{2}]^{1}_{0}\\$

$1 = 2*c-\frac{c}{2}\\$

$\therefore c = \frac{1}{2-\frac{1}{2}} = \frac{2}{3}\\$

### b) 

$F(y)= \int _{-\infty}^{y}(\frac{4}{3}-\frac{2}{3}*y) dy\\$

### c)

$[\frac{4}{3}*y-\frac{2*y^2}{6}]^{0.4}_{0}\\$

```{r}
  f <- function(x) {(4/3)-(2/3)*x}
integrate(f,0,0.4)
```

### d)

$[\frac{4}{3}*y-\frac{2*y^2}{6}]^{0.6}_{0.1}\\$
```{r}
 f <- function(x) {(4/3)-(2/3)*x}
integrate(f,0.1,0.6)
```
## Q 15

### a)
$E(Y) = \int_{-\infty}^{\infty} y*f(y)*dy$
```{r}
 f <- function(x) {x*((3/500)*(25-x^2))}
mu =integrate(f,-5,5)
integrate(f,-5,5)
```

$E(Y^2) = \int_{-\infty}^{\infty} y^2*f(y)*dy$
```{r}
f <- function(x) {x^2*((3/500)*(25-x^2))}
EX2 = integrate(f,-5,5)
integrate(f,-5,5)
```

$Var(Y) = E(Y^2)-E(Y)^2$
```{r}
f <- function(x) {x*((3/500)*(25-x^2))}
mu =c(integrate(f,-5,5))
f <- function(x) {x^2*((3/500)*(25-x^2))}
EX2 = c(integrate(f,-5,5))
Var =EX2$value-mu$value^2 
Var
```

### b)

$E(cX) = cE(X)$

$V(cX) = c^2V(X)$

minutes $c = \frac{1}{60}$

mean (in minutes):

```{r}
 f <- function(x) {x*((3/500)*(25-x^2))}
mu =c(integrate(f,-5,5))
mu$value/60
```

variance (in minutes):

```{r}
f <- function(x) {x^2*((3/500)*(25-x^2))}
EX2 = c(integrate(f,-5,5))
EX2$value/(60^2)
```

### c)

$E(cX) = cE(X)$

$V(cX) = c^2V(X)$

seconds $c = 60$

mean (in seconds):

```{r}
 f <- function(x) {x*((3/500)*(25-x^2))}
mu =c(integrate(f,-5,5))
mu$value*60
```

variance (in seconds):

```{r}
f <- function(x) {x^2*((3/500)*(25-x^2))}
EX2 = c(integrate(f,-5,5))
EX2$value*(60^2)
```

## Q 16

### a)

```{r}
1-pnorm(45,50,3.2)
```
### b)

```{r}
pnorm(55,50,3.2)
```
### c)

```{r}
pnorm(52,50,3.2)-pnorm(51,50,3.2)
```

## Q 17

### a) 

```{r}
pnorm(700,605,185) - pnorm(500,605,185)
```

### b)

```{r}
pnorm(500,605,185)-pnorm(400,605,185)
```

### c)

```{r}
pnorm(850,605,185)
```

### d) 

```{r}
1-pnorm(1000,605,185)
```

### e)


```{r}
qnorm(1-.1,605,185)
```
Only 10 % of crash-tested cars will exceed 842.087 points. 
